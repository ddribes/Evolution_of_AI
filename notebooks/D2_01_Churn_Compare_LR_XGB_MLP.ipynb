{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d209780",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h1 style=\"text-align:center\">Churn Prediction — Comparing Logistic Regression, XGBoost, and a Small MLP</h1>\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "This notebook is designed for a **zero-setup Google Colab classroom** demo:\n",
    "\n",
    "- Train a **Logistic Regression** baseline\n",
    "- Train an **XGBoost** classifier\n",
    "- Train a small **MLP (Neural Network)** with **class imbalance handling** (`class_weight`)\n",
    "- **Tune the decision threshold** on predicted probabilities to maximize:\n",
    "  - **Recall (Churn)** or\n",
    "  - **F1-score (Churn)**\n",
    "- Compare models in a single metrics table\n",
    "\n",
    "> **Target convention:** `0 = Non-churned`, `1 = Churned`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5288db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Install required libraries (Colab) =====\n",
    "!pip -q install xgboost scikit-plot openpyxl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"Versions:\")\n",
    "print(\"  numpy:\", np.__version__)\n",
    "print(\"  pandas:\", pd.__version__)\n",
    "print(\"  sklearn: (imported)\")\n",
    "print(\"  xgboost:\", xgb.__version__)\n",
    "print(\"  tensorflow:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d1c98",
   "metadata": {},
   "source": [
    "## 1) Load the dataset\n",
    "\n",
    "### Option A (recommended for teaching): dataset stored in the GitHub repo\n",
    "\n",
    "If your repo contains:\n",
    "\n",
    "```\n",
    "Evolution_of_AI/\n",
    "  data/Telco_customer_churn.xlsx\n",
    "  notebooks/...\n",
    "```\n",
    "\n",
    "Then the cell below will clone the repo and load the Excel file automatically.\n",
    "\n",
    "### Option B: upload file manually\n",
    "If you do not store the file in GitHub, upload it via the Colab left panel (**Files → Upload**),\n",
    "then set `DATA_PATH` to the uploaded filename.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f624a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Option A: clone your GitHub repo and load the file =====\n",
    "REPO_URL = \"https://github.com/ddribes/Evolution_of_AI.git\"\n",
    "REPO_DIR = \"Evolution_of_AI\"\n",
    "DATA_PATH = f\"{REPO_DIR}/data/Telco_customer_churn.xlsx\"\n",
    "\n",
    "import os, pathlib, subprocess, textwrap\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone -q {REPO_URL}\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find dataset at: {DATA_PATH}\\n\"\n",
    "        \"Either add the file to your repo under data/, or upload it manually and update DATA_PATH.\"\n",
    "    )\n",
    "\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb818f",
   "metadata": {},
   "source": [
    "## 2) Choose the target and build features (X)\n",
    "\n",
    "For churn classification, the most standard target is:\n",
    "\n",
    "- `Churn Value` (0/1)\n",
    "\n",
    "If your dataset uses a different target column, update `TARGET_COL`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc8c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"Churn Value\"\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise KeyError(f\"TARGET_COL='{TARGET_COL}' not found. Available columns include: {list(df.columns)[:20]} ...\")\n",
    "\n",
    "# Drop obvious identifiers (safe defaults; adjust if needed)\n",
    "DROP_COLS = [c for c in [\"CustomerID\", \"Customer ID\", \"customerID\"] if c in df.columns]\n",
    "\n",
    "y = df[TARGET_COL].astype(int).values\n",
    "X = df.drop(columns=[TARGET_COL] + DROP_COLS)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y distribution:\", np.bincount(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e8a77c",
   "metadata": {},
   "source": [
    "## 3) Train/test split + preprocessing\n",
    "\n",
    "We do:\n",
    "- train/test split (stratified)\n",
    "- one-hot encode categorical columns\n",
    "- scale numeric columns\n",
    "\n",
    "Then we can reuse the same `preprocess` pipeline across multiple models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Identify numeric vs categorical columns\n",
    "numeric_cols = X_train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "categorical_cols = [c for c in X_train.columns if c not in numeric_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Numeric columns:\", len(numeric_cols))\n",
    "print(\"Categorical columns:\", len(categorical_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3161a2ac",
   "metadata": {},
   "source": [
    "## 4) Model 1 — Logistic Regression (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e935ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "ypred_logreg = logreg.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression — classification report\")\n",
    "print(classification_report(y_test, ypred_logreg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98723ab6",
   "metadata": {},
   "source": [
    "## 5) Model 2 — XGBoost\n",
    "\n",
    "We train a standard `XGBClassifier`.\n",
    "(We keep it simple for teaching; you can later add GridSearchCV.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15495558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess to numeric matrix for XGBoost and MLP\n",
    "X_train_mat = preprocess.fit_transform(X_train)\n",
    "X_test_mat = preprocess.transform(X_test)\n",
    "\n",
    "# Optional: handle imbalance via scale_pos_weight\n",
    "neg, pos = np.bincount(y_train)\n",
    "scale_pos_weight = neg / pos if pos > 0 else 1.0\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X_train_mat, y_train)\n",
    "\n",
    "ypred_xgb = xgb_clf.predict(X_test_mat)\n",
    "\n",
    "print(\"XGBoost — classification report\")\n",
    "print(classification_report(y_test, ypred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e0f68",
   "metadata": {},
   "source": [
    "## 6) Model 3 — Small MLP (Neural Network) with class imbalance handling\n",
    "\n",
    "We use:\n",
    "- `class_weight` (balanced)\n",
    "- early stopping on validation AUC\n",
    "- sigmoid output for churn probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class_weight from y_train\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "class_weight = {int(c): float(w) for c, w in zip(classes, weights)}\n",
    "class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Ensure dense numeric arrays (some transformers return sparse matrices)\n",
    "# Convert to float32 dense for TensorFlow\n",
    "if hasattr(X_train_mat, \"toarray\"):\n",
    "    X_train_nn = X_train_mat.toarray().astype(\"float32\")\n",
    "    X_test_nn = X_test_mat.toarray().astype(\"float32\")\n",
    "else:\n",
    "    X_train_nn = np.asarray(X_train_mat).astype(\"float32\")\n",
    "    X_test_nn = np.asarray(X_test_mat).astype(\"float32\")\n",
    "\n",
    "mlp = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train_nn.shape[1],)),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.30),\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.20),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "mlp.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[keras.metrics.AUC(name=\"auc\")]\n",
    ")\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_auc\", mode=\"max\", patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = mlp.fit(\n",
    "    X_train_nn, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68edb875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curve (AUC)\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(history.history[\"auc\"], label=\"train AUC\")\n",
    "plt.plot(history.history[\"val_auc\"], label=\"val AUC\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"MLP training curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a1dd8e",
   "metadata": {},
   "source": [
    "## 7) Threshold tuning (maximize Recall or F1 for churn)\n",
    "\n",
    "Instead of using the default threshold 0.5, we tune the threshold on test probabilities.\n",
    "\n",
    "- **Lower threshold** → higher **recall** (catch more churners) but more false alarms\n",
    "- **F1-optimal threshold** → best balance between precision and recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6307b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probabilities for churn = 1\n",
    "proba_mlp = mlp.predict(X_test_nn).ravel()\n",
    "\n",
    "def best_threshold(y_true, proba, objective=\"f1\"):\n",
    "    thresholds = np.linspace(0.05, 0.95, 91)\n",
    "    best_t, best_val = 0.5, -1.0\n",
    "\n",
    "    for t in thresholds:\n",
    "        y_pred = (proba >= t).astype(int)\n",
    "        if objective == \"recall\":\n",
    "            val = recall_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
    "        elif objective == \"f1\":\n",
    "            val = f1_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
    "        else:\n",
    "            raise ValueError(\"objective must be 'f1' or 'recall'\")\n",
    "\n",
    "        if val > best_val:\n",
    "            best_val, best_t = val, t\n",
    "\n",
    "    return float(best_t), float(best_val)\n",
    "\n",
    "t_f1, best_f1 = best_threshold(y_test, proba_mlp, objective=\"f1\")\n",
    "t_rec, best_rec = best_threshold(y_test, proba_mlp, objective=\"recall\")\n",
    "\n",
    "print(\"Best threshold for F1:\", t_f1, \"=> F1:\", best_f1)\n",
    "print(\"Best threshold for Recall:\", t_rec, \"=> Recall:\", best_rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b33267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_at_threshold(y_true, proba, t):\n",
    "    y_pred = (proba >= t).astype(int)\n",
    "    return y_pred\n",
    "\n",
    "ypred_mlp_05 = evaluate_at_threshold(y_test, proba_mlp, 0.5)\n",
    "ypred_mlp_f1 = evaluate_at_threshold(y_test, proba_mlp, t_f1)\n",
    "ypred_mlp_rec = evaluate_at_threshold(y_test, proba_mlp, t_rec)\n",
    "\n",
    "print(\"MLP (threshold=0.50)\")\n",
    "print(classification_report(y_test, ypred_mlp_05))\n",
    "\n",
    "print(\"\\nMLP (best F1 threshold)\")\n",
    "print(classification_report(y_test, ypred_mlp_f1))\n",
    "\n",
    "print(\"\\nMLP (best Recall threshold)\")\n",
    "print(classification_report(y_test, ypred_mlp_rec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecd4f71",
   "metadata": {},
   "source": [
    "## 8) Comparison table (LogReg vs XGBoost vs MLP)\n",
    "\n",
    "We compare **Accuracy**, plus class-1 (**Churn**) Precision/Recall/F1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ebd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_row(model_name, y_true, y_pred):\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision (Churn)\": precision_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
    "        \"Recall (Churn)\": recall_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
    "        \"F1-score (Churn)\": f1_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
    "    }\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    metrics_row(\"Logistic Regression\", y_test, ypred_logreg),\n",
    "    metrics_row(\"XGBoost\", y_test, ypred_xgb),\n",
    "    metrics_row(\"MLP (t=0.50)\", y_test, ypred_mlp_05),\n",
    "    metrics_row(f\"MLP (best F1 t={t_f1:.2f})\", y_test, ypred_mlp_f1),\n",
    "    metrics_row(f\"MLP (best Recall t={t_rec:.2f})\", y_test, ypred_mlp_rec),\n",
    "]).sort_values(by=\"F1-score (Churn)\", ascending=False)\n",
    "\n",
    "comparison.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: visualize comparison\n",
    "plt.figure(figsize=(9,4))\n",
    "tmp = comparison.set_index(\"Model\")[[\"Precision (Churn)\", \"Recall (Churn)\", \"F1-score (Churn)\"]]\n",
    "tmp.plot(kind=\"bar\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Churn metrics comparison (class = 1)\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073fa4d0",
   "metadata": {},
   "source": [
    "## 9) Confusion matrices (optional)\n",
    "\n",
    "This helps students see *what kinds of errors* each model makes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f76350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(cm, title):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, [\"0 (No churn)\", \"1 (Churn)\"], rotation=25)\n",
    "    plt.yticks(tick_marks, [\"0 (No churn)\", \"1 (Churn)\"])\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], \"d\"),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion(confusion_matrix(y_test, ypred_logreg), \"Logistic Regression\")\n",
    "plot_confusion(confusion_matrix(y_test, ypred_xgb), \"XGBoost\")\n",
    "plot_confusion(confusion_matrix(y_test, ypred_mlp_f1), f\"MLP (best F1, t={t_f1:.2f})\")\n",
    "plot_confusion(confusion_matrix(y_test, ypred_mlp_rec), f\"MLP (best Recall, t={t_rec:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d6206e",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "## Takeaway (teaching summary)\n",
    "\n",
    "- **Class imbalance** matters: churners are the minority class.\n",
    "- `class_weight` (MLP) and `scale_pos_weight` (XGBoost) help the model pay more attention to churners.\n",
    "- **Threshold tuning** lets you choose what you optimize:\n",
    "  - maximize **Recall** → catch more churners (more false alarms)\n",
    "  - maximize **F1** → best trade-off between precision and recall\n",
    "- **Accuracy alone is not enough** for churn problems.\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Churn_Compare_LR_XGB_MLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
